{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Sorting Demo\n",
    "In a selected recording, use RT-Sort to \n",
    "\n",
    "1) Detect sequences in the first part of the recording (offline mode)\n",
    "2) Assign spikes in real-time in the second part (online mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No maxlab found, instead using dummy maxlab module!\n",
      "Cannot import torch_tensorrt\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "%autoreload 2\n",
    "from braindance.core.maxwell_env import MaxwellEnv, stop_process_using_port\n",
    "from braindance.core.spikesorter.rt_sort import detect_sequences, RTSort, save_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RT-Sort setup\n",
    "recording_path = \"patch_rec_cell2.raw.h5\"\n",
    "inter_path = \"2602\"\n",
    "detection_model_path = \"braindance/core/spikedetector/detection_models/mea\"\n",
    "offline_recording_window_ms = (0, 5*60*1000)  # Section of recording for detecting sequences (times in milliseconds)\n",
    "num_processes=os.cpu_count()//2  # The optimal num_processes for the fastest computation depends on your system\n",
    "verbose = True  # Whether to print progress\n",
    "\n",
    "online_recording_window_ms = (5*60*1000, 10*60*1000)  # Section of recording for online sorting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect sequences (nothing to change here)\n",
    "rt_sort = detect_sequences(\n",
    "    recording=recording_path,\n",
    "    inter_path=inter_path,\n",
    "    detection_model=detection_model_path,\n",
    "    recording_window_ms=offline_recording_window_ms, \n",
    "    num_processes=num_processes,\n",
    "    verbose=verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot compile detection model with torch_tensorrt because cannot load torch_tensorrt. Skipping NVIDIA compilation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riceh\\anaconda3\\envs\\brain_dance\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:306: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL: Load RT-Sort (helpful if this notebook has been restarted after running the previous cell)\n",
    "#           RT-Sort is saved at inter_path/rt_sort.pickle\n",
    "rt_sort = RTSort.load_from_file(Path(inter_path) / \"rt_sort.pickle\", detection_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving traces:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:07<00:00,  1.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Setup recording for online sorting (nothing to change here)\n",
    "scaled_traces_path = save_traces(recording_path, Path(inter_path) / \"online\",\n",
    "                                *online_recording_window_ms, \n",
    "                                num_processes=num_processes, dtype=\"float32\",\n",
    "                                verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config file specified\n",
      "Launching dummy server\n",
      "====================================\n",
      "Using dummy data: \n",
      "\t C:\\Users\\riceh\\kosik\\data\\2602\\online\\scaled_traces.npy\n",
      "====================================\n",
      "Could not import smart_open_braingeneers, using smart_open\n",
      "Successfully ignored first packet\n",
      "Dummy server ready\n",
      "Initializing MaxOne\n",
      "MaxOne initialized\n",
      "Setting up subscribers\n",
      "Recording electrodes initialized from: None\n",
      "Electrodes selected for stimulation: []\n",
      "Power cycled\n",
      "Offseting\n",
      "Successfully ignored first packet\n",
      "Successfully ignored remaining packets\n",
      "Name of experiment:  \n",
      "At  C:\\Users\\riceh\\kosik\\data\\delete_me\\.raw.h5\n",
      "Recording from 0 channels and 0 stim electrodes\n",
      "===================== Beginning experiment =====================\n",
      "Spike at 0.5275s was assigned to sequence 14\n",
      "Spike at 0.5674s was assigned to sequence 0\n",
      "Spike at 0.6321s was assigned to sequence 18\n",
      "Spike at 0.7192s was assigned to sequence 33\n",
      "Spike at 0.7163s was assigned to sequence 10\n",
      "Spike at 0.7555s was assigned to sequence 5\n",
      "Spike at 0.8594s was assigned to sequence 24\n",
      "Spike at 0.8665s was assigned to sequence 13\n",
      "Spike at 0.8739s was assigned to sequence 14\n",
      "Spike at 0.9334s was assigned to sequence 16\n",
      "Spike at 0.9422s was assigned to sequence 26\n",
      "Spike at 0.9423s was assigned to sequence 12\n",
      "Spike at 1.0494s was assigned to sequence 21\n",
      "Spike at 1.0457s was assigned to sequence 34\n",
      "Spike at 1.0534s was assigned to sequence 6\n",
      "Spike at 1.1004s was assigned to sequence 14\n",
      "Spike at 1.1090s was assigned to sequence 16\n",
      "Spike at 1.1529s was assigned to sequence 6\n",
      "Spike at 1.1864s was assigned to sequence 9\n",
      "Spike at 1.1877s was assigned to sequence 33\n",
      "Spike at 1.2794s was assigned to sequence 28\n",
      "Spike at 1.3195s was assigned to sequence 28\n",
      "Spike at 1.3422s was assigned to sequence 21\n",
      "Spike at 1.4061s was assigned to sequence 33\n",
      "Spike at 1.4726s was assigned to sequence 1\n",
      "Spike at 1.4997s was assigned to sequence 5\n",
      "Spike at 1.5749s was assigned to sequence 21\n",
      "Spike at 1.6047s was assigned to sequence 33\n",
      "Spike at 1.6444s was assigned to sequence 28\n",
      "Spike at 1.6835s was assigned to sequence 5\n",
      "Spike at 1.6863s was assigned to sequence 1\n",
      "Spike at 1.7293s was assigned to sequence 16\n",
      "Spike at 1.7621s was assigned to sequence 14\n",
      "Spike at 1.8587s was assigned to sequence 33\n",
      "Spike at 1.9190s was assigned to sequence 7\n",
      "Spike at 1.9590s was assigned to sequence 7\n",
      "Spike at 1.9625s was assigned to sequence 12\n",
      "Spike at 1.9970s was assigned to sequence 24\n",
      "Spike at 2.0607s was assigned to sequence 22\n",
      "Spike at 2.0650s was assigned to sequence 5\n",
      "Spike at 2.0907s was assigned to sequence 28\n",
      "Spike at 2.1028s was assigned to sequence 21\n",
      "Spike at 2.1143s was assigned to sequence 33\n",
      "Spike at 2.1368s was assigned to sequence 14\n",
      "Spike at 2.1582s was assigned to sequence 27\n",
      "Spike at 2.1614s was assigned to sequence 36\n",
      "Spike at 2.1620s was assigned to sequence 12\n",
      "Spike at 2.1624s was assigned to sequence 23\n",
      "Spike at 2.1742s was assigned to sequence 16\n",
      "Spike at 2.2492s was assigned to sequence 24\n",
      "Spike at 2.2684s was assigned to sequence 28\n",
      "Spike at 2.3181s was assigned to sequence 0\n",
      "Spike at 2.4234s was assigned to sequence 10\n",
      "Spike at 2.4790s was assigned to sequence 5\n",
      "Spike at 2.5421s was assigned to sequence 14\n",
      "Spike at 2.5488s was assigned to sequence 33\n",
      "Spike at 2.5883s was assigned to sequence 12\n",
      "Spike at 2.5886s was assigned to sequence 25\n",
      "Spike at 2.7376s was assigned to sequence 9\n",
      "Spike at 2.7621s was assigned to sequence 6\n",
      "Spike at 2.8052s was assigned to sequence 5\n",
      "Spike at 2.8996s was assigned to sequence 4\n",
      "Spike at 2.9946s was assigned to sequence 14\n",
      "Spike at 2.9926s was assigned to sequence 24\n",
      "Spike at 3.0179s was assigned to sequence 6\n",
      "Spike at 3.1587s was assigned to sequence 28\n",
      "Spike at 3.1548s was assigned to sequence 1\n",
      "Spike at 3.2664s was assigned to sequence 33\n",
      "Spike at 3.2907s was assigned to sequence 32\n",
      "Spike at 3.2993s was assigned to sequence 27\n",
      "Spike at 3.5032s was assigned to sequence 5\n",
      "Spike at 3.5061s was assigned to sequence 16\n",
      "Spike at 3.5170s was assigned to sequence 14\n",
      "Spike at 3.5504s was assigned to sequence 6\n",
      "Spike at 3.6505s was assigned to sequence 33\n",
      "Spike at 3.7279s was assigned to sequence 24\n",
      "Spike at 3.7319s was assigned to sequence 16\n",
      "Spike at 3.7624s was assigned to sequence 28\n",
      "Spike at 3.7799s was assigned to sequence 0\n",
      "Spike at 3.8144s was assigned to sequence 27\n",
      "Spike at 3.8787s was assigned to sequence 21\n",
      "Spike at 3.9383s was assigned to sequence 34\n",
      "Spike at 4.0358s was assigned to sequence 3\n",
      "Spike at 4.0408s was assigned to sequence 28\n",
      "Spike at 4.0761s was assigned to sequence 14\n",
      "Spike at 4.0966s was assigned to sequence 6\n",
      "Spike at 4.2858s was assigned to sequence 14\n",
      "Spike at 4.4662s was assigned to sequence 22\n",
      "Spike at 4.5856s was assigned to sequence 13\n",
      "Spike at 4.6135s was assigned to sequence 24\n",
      "Spike at 4.6288s was assigned to sequence 5\n",
      "Spike at 4.6326s was assigned to sequence 28\n",
      "Spike at 4.6443s was assigned to sequence 9\n",
      "Spike at 4.6508s was assigned to sequence 10\n",
      "Spike at 4.6559s was assigned to sequence 21\n",
      "Spike at 4.6641s was assigned to sequence 28\n",
      "Spike at 4.6596s was assigned to sequence 0\n",
      "Spike at 4.7151s was assigned to sequence 27\n",
      "Spike at 4.7469s was assigned to sequence 0\n",
      "Spike at 4.7728s was assigned to sequence 14\n",
      "Spike at 4.7720s was assigned to sequence 6\n",
      "Spike at 4.7719s was assigned to sequence 36\n",
      "Spike at 4.7721s was assigned to sequence 12\n",
      "Spike at 4.8823s was assigned to sequence 33\n",
      "Spike at 4.9121s was assigned to sequence 5\n",
      "Spike at 4.9909s was assigned to sequence 27\n",
      "Spike at 5.0842s was assigned to sequence 18\n",
      "Spike at 5.1279s was assigned to sequence 3\n",
      "Spike at 5.1334s was assigned to sequence 28\n",
      "Spike at 5.1339s was assigned to sequence 5\n",
      "Max time 5 reached at 5.005367500009015\n"
     ]
    }
   ],
   "source": [
    "# Set up params for online sorting\n",
    "maxwell_params = {\n",
    "    # Total duration of online sorting in seconds\n",
    "    \"max_time_sec\": 5, # (online_recording_window_ms[1] - online_recording_window_ms[0]) / 1000, \n",
    "    \n",
    "    # An empty folder will be created at this path. For this notebook, this folder can be deleted\n",
    "    \"save_dir\": \"save_dir\",\n",
    "\n",
    "    # If the computer is not connected to a physical MEA, set \"dummy\" to path of recording to simulate a real recording. Otherwise, set to None.\n",
    "    \"dummy\": Path(inter_path) / \"online/scaled_traces.npy\",\n",
    "    \n",
    "    \"config\": None,\n",
    "    \"stim_electrodes\": [],\n",
    "    \"multiprocess\": False,\n",
    "    \"render\": False,\n",
    "    \"observation_type\": \"raw\",\n",
    "}\n",
    "done = False\n",
    "\n",
    "# Start online sorting\n",
    "rt_sort.reset()\n",
    "env = MaxwellEnv(**maxwell_params)\n",
    "\n",
    "sequence_detections = [[] for _ in range(rt_sort.num_seqs)]\n",
    "\n",
    "while not done:\n",
    "    obs, done = env.step(buffer_size=rt_sort.buffer_size)    \n",
    "    rt_sort.latest_frame = env.latest_frame - len(obs) + 1\n",
    "    detections = rt_sort.running_sort(obs)\n",
    "    for sequence_idx, spike_time in detections:\n",
    "        print(f\"Spike at {spike_time/1000:.4f}s was assigned to sequence {sequence_idx}\")\n",
    "        sequence_detections[sequence_idx].append(spike_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_dance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

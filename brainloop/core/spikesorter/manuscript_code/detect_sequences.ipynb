{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Detect and save sequences in pre-recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set RECORDING_PATH to the .h5 pre-recording.\n",
    "Set ROOT_PATH to a folder where intermediate results of RT-Sort and the final RT-Sort object will be saved\n",
    "    The RT-Sort object will be saved to ROOT_PATH / \"rt_sort.pickle\"\n",
    "    Set ROOT_PATH_MODEL to a folder where the detection model's outputs are saved\n",
    "Set MODEL_PATH to the path of the detection model that will be used\n",
    "\n",
    "Then run the next cell\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "RECORDING_PATH = \"data.raw.h5\"\n",
    "ROOT_PATH = Path(\"/data/MEAprojects/BrainDance/braindance/core/data/test_rt_sort2.2\")\n",
    "ROOT_PATH_MODEL = ROOT_PATH / \"dl_model\"\n",
    "MODEL_PATH = Path(\"/data/MEAprojects/BrainDance/braindance/core/spikedetector/model_0_4_4_5118\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MKL_NUM_THREADS=1\n",
      "env: NUMEXPR_NUM_THREADS=1\n",
      "env: OMP_NUM_THREADS=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mea/anaconda3/envs/brain_dance/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mea/anaconda3/envs/brain_dance/lib/python3.11/site-packages/torch_tensorrt/fx/tracer/acc_tracer/acc_ops.py:895: UserWarning: Unable to import torchvision related libraries.: operator torchvision::nms does not exist. Please install torchvision lib in order to lower stochastic_depth\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-recording is greater than five minutes. Using last five minutes to detect sequences\n",
      "Alllocating memory for traces ...\n",
      "Extracting traces ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:08<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DL model ...\n",
      "Allocating memory to save model traces and outputs ...\n",
      "Inference scaling: 1.8\n",
      "Running model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49999/49999 [01:47<00:00, 466.83it/s]\n",
      "100%|██████████| 5999/5999 [00:46<00:00, 130.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to run DL model: 191.92171239852905 seconds\n",
      "3014252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 772/772 [01:11<00:00, 10.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 sequences before merging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59980/59980 [01:59<00:00, 500.64it/s]\n",
      "100%|██████████| 131/131 [00:10<00:00, 12.35it/s]\n",
      "100%|██████████| 43/43 [00:00<00:00, 45.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 sequences after first merging\n",
      "\n",
      "Merged 22 with 41\n",
      "Latency diff: 0.15. Amp median diff: 0.08\n",
      "Amp dist p-value 0.3838\n",
      "#spikes:\n",
      "Merge base: 240, Add: 363, Overlaps: 1\n",
      "After merging: 602\n",
      "\n",
      "Merged 44 with 42\n",
      "Latency diff: 0.17. Amp median diff: 0.12\n",
      "Amp dist p-value 0.8291\n",
      "#spikes:\n",
      "Merge base: 752, Add: 480, Overlaps: 5\n",
      "After merging: 1229\n",
      "\n",
      "Merged 43 with [44, 42]\n",
      "Latency diff: 0.20. Amp median diff: 0.10\n",
      "Amp dist p-value 0.1936\n",
      "#spikes:\n",
      "Merge base: 777, Add: 1229, Overlaps: 12\n",
      "After merging: 1987\n",
      "\n",
      "Merged [22, 41] with 38\n",
      "Latency diff: 0.25. Amp median diff: 0.13\n",
      "Amp dist p-value 0.7036\n",
      "#spikes:\n",
      "Merge base: 602, Add: 117, Overlaps: 8\n",
      "After merging: 711\n",
      "\n",
      "Merged 31 with 39\n",
      "Latency diff: 0.35. Amp median diff: 0.15\n",
      "Amp dist p-value 2.8477\n",
      "#spikes:\n",
      "Merge base: 21, Add: 198, Overlaps: 1\n",
      "After merging: 218\n",
      "\n",
      "Merged 20 with 29\n",
      "Latency diff: 0.75. Amp median diff: 0.08\n",
      "Amp dist p-value 0.1952\n",
      "#spikes:\n",
      "Merge base: 128, Add: 65, Overlaps: 29\n",
      "After merging: 165\n",
      "\n",
      "Merged 11 with 15\n",
      "Latency diff: 0.14. Amp median diff: 0.20\n",
      "Amp dist p-value 1.0312\n",
      "#spikes:\n",
      "Merge base: 208, Add: 195, Overlaps: 0\n",
      "After merging: 397\n",
      "\n",
      "Merged 35 with 25\n",
      "Latency diff: 0.45. Amp median diff: 0.15\n",
      "Amp dist p-value 0.8931\n",
      "#spikes:\n",
      "Merge base: 60, Add: 91, Overlaps: 0\n",
      "After merging: 151\n",
      "\n",
      "Merged 2 with 12\n",
      "Latency diff: 0.48. Amp median diff: 0.15\n",
      "Amp dist p-value 0.2404\n",
      "#spikes:\n",
      "Merge base: 31, Add: 61, Overlaps: 0\n",
      "After merging: 92\n",
      "\n",
      "Merged 30 with [2, 12]\n",
      "Latency diff: 0.26. Amp median diff: 0.15\n",
      "Amp dist p-value 0.0019\n",
      "#spikes:\n",
      "Merge base: 92, Add: 92, Overlaps: 2\n",
      "After merging: 179\n",
      "\n",
      "Merged [11, 15] with 3\n",
      "Latency diff: 0.28. Amp median diff: 0.20\n",
      "Amp dist p-value 0.8301\n",
      "#spikes:\n",
      "Merge base: 397, Add: 74, Overlaps: 1\n",
      "After merging: 466\n",
      "\n",
      "Merged 23 with 1\n",
      "Latency diff: 0.66. Amp median diff: 0.19\n",
      "Amp dist p-value 0.9072\n",
      "#spikes:\n",
      "Merge base: 237, Add: 36, Overlaps: 0\n",
      "After merging: 273\n",
      "\n",
      "Merged 27 with 14\n",
      "Latency diff: 0.81. Amp median diff: 0.18\n",
      "Amp dist p-value 1.3330\n",
      "#spikes:\n",
      "Merge base: 142, Add: 61, Overlaps: 0\n",
      "After merging: 203\n",
      "\n",
      "Merged [20, 29] with 19\n",
      "Latency diff: 1.40. Amp median diff: 0.13\n",
      "Amp dist p-value 0.9185\n",
      "#spikes:\n",
      "Merge base: 165, Add: 30, Overlaps: 5\n",
      "After merging: 188\n",
      "\n",
      "Merged 33 with [31, 39]\n",
      "Latency diff: 1.63. Amp median diff: 0.10\n",
      "Amp dist p-value 0.1183\n",
      "#spikes:\n",
      "Merge base: 153, Add: 218, Overlaps: 3\n",
      "After merging: 367\n",
      "\n",
      "Merged 36 with [35, 25]\n",
      "Latency diff: 1.25. Amp median diff: 0.55\n",
      "Amp dist p-value 0.2306\n",
      "#spikes:\n",
      "Merge base: 238, Add: 151, Overlaps: 3\n",
      "After merging: 386\n",
      "\n",
      "Merged 28 with 4\n",
      "Latency diff: 2.03. Amp median diff: 0.57\n",
      "Amp dist p-value 0.0303\n",
      "#spikes:\n",
      "Merge base: 23, Add: 35, Overlaps: 0\n",
      "After merging: 58\n",
      "\n",
      "Formed 28 merged clusters:\n",
      "cluster 0: 0\n",
      "cluster 1: 5\n",
      "cluster 2: 6\n",
      "cluster 3: 7\n",
      "cluster 4: 8\n",
      "cluster 5: 9\n",
      "cluster 6: 10\n",
      "cluster 7: [11, 15, 3]\n",
      "cluster 8: 13\n",
      "cluster 9: 16\n",
      "cluster 10: 17\n",
      "cluster 11: 18\n",
      "cluster 12: [20, 29, 19]\n",
      "cluster 13: 21\n",
      "cluster 14: [22, 41, 38]\n",
      "cluster 15: [23, 1]\n",
      "cluster 16: 24\n",
      "cluster 17: 26\n",
      "cluster 18: [27, 14]\n",
      "cluster 19: [28, 4]\n",
      "cluster 20: [30, 2, 12]\n",
      "cluster 21: 32\n",
      "cluster 22: [33, 31, 39]\n",
      "cluster 23: 34\n",
      "cluster 24: [36, 35, 25]\n",
      "cluster 25: 37\n",
      "cluster 26: 40\n",
      "cluster 27: [43, 44, 42]\n",
      "25 sequences after second merging\n",
      "Time to detect sequences: 405.35764718055725 seconds\n"
     ]
    }
   ],
   "source": [
    "%env MKL_NUM_THREADS=1\n",
    "%env NUMEXPR_NUM_THREADS=1\n",
    "%env OMP_NUM_THREADS=1\n",
    "\n",
    "%load_ext autoreload\n",
    "from copy import deepcopy\n",
    "from importlib import reload\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from spikeinterface.extractors import MaxwellRecordingExtractor\n",
    "\n",
    "%autoreload 2\n",
    "from braindance.core.spikesorter.manuscript_code import utils\n",
    "from braindance.core.spikesorter.manuscript_code import si_rec13 as F  # This forces you to manually reload every time modification happens (prevents forgetfulness errors)\n",
    "# from src.sorters.base import Unit\n",
    "\n",
    "from braindance.core.spikedetector.model2 import ModelSpikeSorter\n",
    "# Load recording\n",
    "RECORDING = MaxwellRecordingExtractor(RECORDING_PATH)\n",
    "SAMP_FREQ = round(RECORDING.get_sampling_frequency() / 1000)  # kHz\n",
    "NUM_ELECS = RECORDING.get_num_channels()\n",
    "ELEC_LOCS = RECORDING.get_channel_locations()\n",
    "\n",
    "assert SAMP_FREQ <= 35, \"SAMP_FREQ must be in kHz\"\n",
    "if SAMP_FREQ not in {20, 30}:\n",
    "    print(\"NEED TO CHANGE FRONT_BUFFER AND OUTPUT_WINDOW_HALF_SIZE TO MODEL'S VALUES\")\n",
    "if RECORDING.get_total_duration() >= 5 * 60:  # Recording is greater than five minutes\n",
    "    training_duration_ms = RECORDING.get_total_samples(\n",
    "    ) / RECORDING.get_sampling_frequency() * 1000\n",
    "    TRAINING_MS = (training_duration_ms - 5*60*1000, training_duration_ms)  # Last 5 minute of first patch\n",
    "    TRACES_TRAINING_MS = (50, 5*60*1000)  # Rel to scaled_traces\n",
    "    print(\"Pre-recording is greater than five minutes. Using last five minutes to detect sequences\")\n",
    "else:\n",
    "    TRAINING_MS = (0, RECORDING.get_total_duration() * 1000)\n",
    "    TRACES_TRAINING_MS = (50, RECORDING.get_total_duration() * 1000)\n",
    "    \n",
    "TESTING_MS = (-1, -1)  # Not used for patch recordings\n",
    "# TESTING_MS = (training_duration_ms, RECORDING.get_total_duration() * 1000)  # 5 min to 10 min in recording (in ms)\n",
    "STRINGENT_THRESH = 0.275\n",
    "STRINGENT_THRESH_LOGIT = F.sigmoid_inverse(STRINGENT_THRESH)\n",
    "LOOSE_THRESH = 0.1 \n",
    "LOOSE_THRESH_LOGIT = F.sigmoid_inverse(LOOSE_THRESH)\n",
    "\n",
    "INFERENCE_SCALING_NUMERATOR = 12.6 \n",
    "\n",
    "FRONT_BUFFER = round(2*SAMP_FREQ)\n",
    "OUTPUT_WINDOW_HALF_SIZE = round(3*SAMP_FREQ)\n",
    "PRE_MEDIAN_FRAMES = round(50 * SAMP_FREQ)\n",
    "\n",
    "## No user inputs below\n",
    "ROOT_PATH.mkdir(exist_ok=True, parents=True)\n",
    "ROOT_PATH_MODEL.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "SCALED_TRACES_PATH = ROOT_PATH_MODEL / \"scaled_traces.npy\"\n",
    "\n",
    "MODEL_TRACES_PATH = ROOT_PATH_MODEL / \"model_traces.npy\"\n",
    "MODEL_OUTPUTS_PATH = ROOT_PATH_MODEL / \"model_outputs.npy\" \n",
    "\n",
    "ALL_CROSSINGS_PATH  = ROOT_PATH_MODEL / \"all_crossings.npy\"\n",
    "ELEC_CROSSINGS_IND_PATH = ROOT_PATH_MODEL / \"elec_crossings_ind.npy\"\n",
    "F.RECORDING = RECORDING\n",
    "F.NUM_ELECS = NUM_ELECS\n",
    "F.ELEC_LOCS = ELEC_LOCS\n",
    "F.SAMP_FREQ = SAMP_FREQ\n",
    "F.FRONT_BUFFER = FRONT_BUFFER\n",
    "F.INFERENCE_SCALING_NUMERATOR = INFERENCE_SCALING_NUMERATOR\n",
    "F.PRE_MEDIAN_FRAMES = PRE_MEDIAN_FRAMES\n",
    "# For RT-Sort manuscript: measure time to detect sequences\n",
    "import time\n",
    "\n",
    "class Stopwatch:\n",
    "    def __init__(self):\n",
    "        self.duration = 0\n",
    "        self.start_time = 0\n",
    "    def start(self):\n",
    "        self.start_time = time.time()\n",
    "    def stop(self):\n",
    "        stop_time = time.time()\n",
    "        self.duration += stop_time - self.start_time\n",
    "\n",
    "stopwatch = Stopwatch()\n",
    "stopwatch.start()\n",
    "F.save_traces_mea_new(RECORDING_PATH, SCALED_TRACES_PATH, start_ms=TRAINING_MS[0], end_ms=TRAINING_MS[1])\n",
    "stopwatch.stop()\n",
    "\n",
    "stopwatch.start()\n",
    "model = ModelSpikeSorter.load(MODEL_PATH)\n",
    "model.compile(NUM_ELECS, MODEL_PATH)\n",
    "stopwatch.stop()\n",
    "\n",
    "stopwatch.start()\n",
    "F.run_dl_model(MODEL_PATH, SCALED_TRACES_PATH, MODEL_TRACES_PATH, MODEL_OUTPUTS_PATH)\n",
    "stopwatch.stop()\n",
    "\n",
    "stopwatch.start()\n",
    "F.NUM_ELECS = NUM_ELECS\n",
    "F.SAMP_FREQ = SAMP_FREQ\n",
    "F.FRONT_BUFFER = FRONT_BUFFER\n",
    "F.STRINGENT_THRESH = STRINGENT_THRESH\n",
    "F.STRINGENT_THRESH_LOGIT = STRINGENT_THRESH_LOGIT\n",
    "F.extract_crossings(MODEL_OUTPUTS_PATH, ALL_CROSSINGS_PATH,\n",
    "                    ELEC_CROSSINGS_IND_PATH)\n",
    "stopwatch.stop()\n",
    "print(f\"Time to run DL model: {stopwatch.duration} seconds\")\n",
    "\n",
    "# Sanity check that there are stringent detections\n",
    "# print(len(np.load(ALL_CROSSINGS_PATH, allow_pickle=True)))\n",
    "stopwatch.start()\n",
    "\n",
    "# No user inputs here. Run after running DL model\n",
    "ALL_CLOSEST_ELECS = []\n",
    "for elec in range(NUM_ELECS):\n",
    "    elec_ind = []\n",
    "    dists = []\n",
    "    x1, y1 = ELEC_LOCS[elec]\n",
    "    for elec2 in range(RECORDING.get_num_channels()):\n",
    "        if elec == elec2:\n",
    "            continue\n",
    "        x2, y2 = ELEC_LOCS[elec2]\n",
    "        dists.append(np.sqrt((x2 - x1)**2 + (y2 - y1)**2))\n",
    "        elec_ind.append(elec2)\n",
    "    order = np.argsort(dists)\n",
    "    ALL_CLOSEST_ELECS.append(np.array(elec_ind)[order])   \n",
    "# \n",
    "TRACES = np.load(MODEL_TRACES_PATH, mmap_mode=\"r\")\n",
    "FILT_TRACES = np.load(SCALED_TRACES_PATH, mmap_mode=\"r\")  # called FILT_TRACES, but these are not actually filtered\n",
    "OUTPUTS = np.load(MODEL_OUTPUTS_PATH, mmap_mode=\"r\")\n",
    "ALL_CROSSINGS = np.load(ALL_CROSSINGS_PATH, allow_pickle=True)\n",
    "ELEC_CROSSINGS_IND = np.load(ELEC_CROSSINGS_IND_PATH, allow_pickle=True)\n",
    "\n",
    "ALL_CROSSINGS = [tuple(cross) for cross in ALL_CROSSINGS]\n",
    "ELEC_CROSSINGS_IND = [tuple(ind) for ind in ELEC_CROSSINGS_IND]  # [(elec's cross times ind in all_crossings)]\n",
    "\n",
    "stopwatch.stop()\n",
    "# Set global variables in .py\n",
    "reload(F)\n",
    "\n",
    "F.RECORDING = RECORDING\n",
    "F.MEA = True\n",
    "F.STRINGENT_THRESH = STRINGENT_THRESH\n",
    "F.STRINGENT_THRESH_LOGIT = STRINGENT_THRESH_LOGIT\n",
    "F.LOOSE_THRESH = LOOSE_THRESH\n",
    "F.LOOSE_THRESH_LOGIT = LOOSE_THRESH_LOGIT\n",
    "F.INFERENCE_SCALING_NUMERATOR = INFERENCE_SCALING_NUMERATOR\n",
    "\n",
    "# F.CHANS_RMS = CHANS_RMS\n",
    "F.SAMP_FREQ = SAMP_FREQ\n",
    "F.NUM_ELECS = NUM_ELECS\n",
    "F.ELEC_LOCS = ELEC_LOCS\n",
    "\n",
    "F.ALL_CLOSEST_ELECS = ALL_CLOSEST_ELECS\n",
    "\n",
    "F.FRONT_BUFFER = FRONT_BUFFER\n",
    "F.OUTPUT_WINDOW_HALF_SIZE = OUTPUT_WINDOW_HALF_SIZE\n",
    "\n",
    "F.N_BEFORE = F.N_AFTER = round(0.5 * SAMP_FREQ)  # Window for looking for electrode codetections\n",
    "F.MIN_ELECS_FOR_ARRAY_NOISE = max(100, round(0.1 * NUM_ELECS))\n",
    "F.MIN_ELECS_FOR_SEQ_NOISE = max(50, round(0.05 * NUM_ELECS))\n",
    "F.PRE_MEDIAN_FRAMES = PRE_MEDIAN_FRAMES\n",
    "\n",
    "F.MIN_ACTIVITY = 0.05 * (TRAINING_MS[1] - TRAINING_MS[0]) / 1000\n",
    "\n",
    "# If doing on new recording, these should be set after ## Full run - DL model\n",
    "F.TRACES = TRACES\n",
    "F.OUTPUTS = OUTPUTS\n",
    "F.ALL_CROSSINGS = ALL_CROSSINGS\n",
    "F.ELEC_CROSSINGS_IND = ELEC_CROSSINGS_IND\n",
    "\n",
    "# Different parameters for MEA\n",
    "F.MIN_AMP_DIST_P = -1\n",
    "F.MAX_AMP_MEDIAN_DIFF_SPIKES = F.MAX_AMP_MEDIAN_DIFF_SEQUENCES = 0.65\n",
    "F.MAX_LATENCY_DIFF_SPIKES = F.MAX_LATENCY_DIFF_SEQUENCES = 3.5\n",
    "F.CLIP_LATENCY_DIFF = 7\n",
    "F.CLIP_AMP_MEDIAN_DIFF = 1.3\n",
    "F.MAX_ROOT_AMP_MEDIAN_STD_SPIKES = 2.5\n",
    "F.MAX_ROOT_AMP_MEDIAN_STD_SEQUENCES = np.inf\n",
    "stopwatch.start()\n",
    "\n",
    "MIN_SPIKES = max(10, 0.05 * (TRAINING_MS[1] - TRAINING_MS[0]) / 1000)\n",
    "\n",
    "##\n",
    "all_clusters = F.form_all_clusters(TRACES_TRAINING_MS)\n",
    "# utils.pickle_dump(all_clusters, ROOT_PATH / \"all_clusters.pickle\")\n",
    "# all_clusters = utils.pickle_load(ROOT_PATH / \"all_clusters.pickle\")\n",
    "\n",
    "all_clusters_reassigned = F.reassign_spikes(all_clusters, TRACES_TRAINING_MS, MIN_SPIKES)\n",
    "# utils.pickle_dump(all_clusters_reassigned, ROOT_PATH / \"all_clusters_reassigned.pickle\")\n",
    "# all_clusters_reassigned = utils.pickle_load(ROOT_PATH / \"all_clusters_reassigned.pickle\")\n",
    "\n",
    "intra_merged_clusters = F.intra_merge(all_clusters_reassigned) \n",
    "trained_sequences = F.inter_merge(intra_merged_clusters, MIN_SPIKES)\n",
    "# utils.pickle_dump(trained_sequences, ROOT_PATH / \"trained_sequences.pickle\")\n",
    "# trained_sequences = utils.pickle_load(ROOT_PATH / \"trained_sequences.pickle\")\n",
    "stopwatch.stop()\n",
    "print(f\"Time to detect sequences: {stopwatch.duration} seconds\")\n",
    "\n",
    "# Save data\n",
    "utils.pickle_dump(all_clusters, ROOT_PATH / \"all_clusters.pickle\")\n",
    "utils.pickle_dump(all_clusters_reassigned, ROOT_PATH / \"all_clusters_reassigned.pickle\")\n",
    "utils.pickle_dump(trained_sequences, ROOT_PATH / \"trained_sequences.pickle\")\n",
    "\n",
    "rt_sort = F.RTSort(trained_sequences, model, SCALED_TRACES_PATH)\n",
    "rt_sort.save(ROOT_PATH / \"rt_sort.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

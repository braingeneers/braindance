"use strict";(self.webpackChunkbraindance_docs=self.webpackChunkbraindance_docs||[]).push([[683],{180:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>i,metadata:()=>a,toc:()=>l});var t=r(4848),s=r(8453);const i={sidebar_position:2},o="Sequence Detection (Offline Use)",a={id:"RT-sort/usage/sequence-detection",title:"Sequence Detection (Offline Use)",description:"RT-Sort can be used for offline sequence detection with a pre-trained detection model. Here's how to do it for both Maxwell MEAs and Neuropixels.",source:"@site/docs/RT-sort/usage/sequence-detection.md",sourceDirName:"RT-sort/usage",slug:"/RT-sort/usage/sequence-detection",permalink:"/BrainDance/docs/RT-sort/usage/sequence-detection",draft:!1,unlisted:!1,editUrl:"https://github.com/braingeneers/braindance/docs/RT-sort/usage/sequence-detection.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Loading Detection Models",permalink:"/BrainDance/docs/RT-sort/usage/load-detection-model"},next:{title:"Real-time Application (Online Use)",permalink:"/BrainDance/docs/RT-sort/usage/real-time-application"}},c={},l=[{value:"Maxwell MEAs",id:"maxwell-meas",level:2},{value:"Parameters",id:"parameters",level:3},{value:"Optional Parameters",id:"optional-parameters",level:3},{value:"Returns",id:"returns",level:3},{value:"Example",id:"example",level:3},{value:"Neuropixels",id:"neuropixels",level:2},{value:"Next Steps",id:"next-steps",level:2}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"sequence-detection-offline-use",children:"Sequence Detection (Offline Use)"})}),"\n",(0,t.jsx)(n.p,{children:"RT-Sort can be used for offline sequence detection with a pre-trained detection model. Here's how to do it for both Maxwell MEAs and Neuropixels."}),"\n",(0,t.jsx)(n.h2,{id:"maxwell-meas",children:"Maxwell MEAs"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from braindance.core.spikesorter.rt_sort import detect_sequences\n\nrt_sort = detect_sequences(recording, inter_path, detection_model, **kwargs)\n"})}),"\n",(0,t.jsx)(n.h3,{id:"parameters",children:"Parameters"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"recording"}),": Recording loaded with SpikeInterface or a path to a saved recording (str or pathlib.Path)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"inter_path"}),": Path to a folder where RT-Sort's intermediate cached data is stored."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"detection_model"}),": ModelSpikeSorter object or a path to a folder containing a ModelSpikeSorter object's files."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"optional-parameters",children:"Optional Parameters"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"recording_window_ms"}),": Tuple (start_ms, end_ms) indicating which section of the recording to run RT-Sort. Default is None (entire duration)."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"delete_inter"}),": Whether to delete the directory inter_path and its contents. Default is False."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"verbose"}),": Whether to print progress of RT-Sort. Default is True."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"num_processes"}),": Number of CPU processes to use. Default is None (uses all available logical CPUs)."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"returns",children:"Returns"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["If ",(0,t.jsx)(n.code,{children:"return_spikes=False"})," (default): Returns an RTSort object."]}),"\n",(0,t.jsxs)(n.li,{children:["If ",(0,t.jsx)(n.code,{children:"return_spikes=True"}),": Returns a NumPy array of shape (num_sequences,) where each element is a NumPy array containing a sequence's spike train."]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"example",children:"Example"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Detect sequences in the first 5 minutes of a recording\nrt_sort = detect_sequences(recording, inter_path, detection_model, recording_window_ms=(0, 5*60*1000))\n\n# Assign spikes in the next 5 minutes\nsequence_spike_trains = rt_sort.sort_offline(recording, inter_path, recording_window_ms=(5*60*1000, 10*60*1000), verbose=True)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"neuropixels",children:"Neuropixels"}),"\n",(0,t.jsx)(n.p,{children:"The process for Neuropixels is similar to Maxwell MEAs, with one key difference:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"from braindance.core.spikesorter.rt_sort import detect_sequences, neuropixels_params\n\nrt_sort = detect_sequences(recording, inter_path, detection_model, **neuropixels_params, **kwargs)\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Use the ",(0,t.jsx)(n.code,{children:"neuropixels_params"})," dictionary to pass Neuropixels-specific RT-Sort parameters. It's also recommended to use a Neuropixels-specific detection model."]}),"\n",(0,t.jsx)(n.h2,{id:"next-steps",children:"Next Steps"}),"\n",(0,t.jsxs)(n.p,{children:["After detecting sequences, you can proceed to ",(0,t.jsx)(n.a,{href:"real-time-application",children:"real-time application"})," or ",(0,t.jsx)(n.a,{href:"training-models",children:"training your own models"}),"."]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,r)=>{r.d(n,{R:()=>o,x:()=>a});var t=r(6540);const s={},i=t.createContext(s);function o(e){const n=t.useContext(i);return t.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),t.createElement(i.Provider,{value:n},e.children)}}}]);